# CSDN_pageviews_spider_tomysql_and_visualize
CSDN爬虫+远程服务器MySQL存储+数据可视化
##首先：修改配置文件——账号、数据库账号和密码、博客总页面和起始页面、删掉id文件
**哇，我竟然也犯了一个致命的错误!将含有数据库信息的代码传到的GitHub上，简直要命啊，还好我的数据库垃圾，是个人的，要是公司或者是机构的，简直凉凉**
##主函数(main.py)：

- 1、导入模块
- 2、获取上次运行时，博客数据集的id，如果没有，则自动设置为1.并在后期创建。
- 3、进入主循环，每30分钟实例化一个博客集(Blog_set),传入id，起始爬取页面和最终爬取页面：
	 - 1、初始化博客集，属性有：博客集的id、采集时间
	 - 2、获取博客数据,调用(notouch_spider.py):
		  - 1、拿到主界面（这里简单说一下吧，基本的爬虫知识）:
			 - 1、修改你的账号，设置初始URL，然后根据你博客主页页面数，依次获取网页信息
			 - 2、尝试两次请求获取网页，增加程序的鲁棒性。避免因为网络原因，导致程序中断。
			 - 3、通过beautifulsoup4进行提取有用信息，其实也可以用正则的，但是我感觉正则的通用性不太好，就换成了bs4。
			 - 4、具体的正则提取我的 刷访问量 的代码中会有。自己百度应该也可以看到
		 - 2、提取有效信息，存入列表
			 - 1、在bs4中，提取到含有单个博客的框——"article-item-box csdn-tracking-statistics"，拿到这个就是可以拿到内容了
			 - 2、在for循环中，提取到更细致的信息——博客id、博客URL、标题、访问量和创建时间
			 - 3、其中标题的处理是比较复杂的，我不断的print，然后尝试，才整出这样的代码
			 - 4、其他的都比较简单了~直接函数就可以获取到，加个编码就好了。
			 - 5、还有一个数据采集时间，这儿是单独提取的。
		 - 3、实例化博客类：
			 - 1、每次拿到一个博客的数据，就实例化一个博客类；
			 - 2、属性有：博客序号num、博客id、标题title、访问量page_view、创建时间create_time
			 - 3、将实例化的博客类，赋值给一个变量blog_i，这个i需要特殊处理
			 - 4、每次将这个变量，加到博客类的列表中。并且作为返回值
		 - 4、就OK了。
	 - 3、将博客信息存储到MySQL数据库，调用(blog2mysql)，这里存的是每个博客的详细信息:
		 - 1、导入pymysql模块，需要预先创建数据库名为"csdn",最好配合Navicat使用。
		 - 2、先是创建表的函数：连接IP、数据库、创建表，这里我用的本地，数据库名称"csdn",表是table_id，id也是一个变量转换的
		 - 3、再是提交数据的函数：连接数据库，获取光标，转换格式，提交信息，用的replace语句，具体的可以看代码，这个比insert要好些。
		 - 4、注意编码和引号的问题，挺复杂的，我试坑了好久
		
	
 - 4、调用set_insert2mysql.set_main函数，将博客集信息存储到MySQL中:
	 - 1、同上，需要创建一个数据库，"blogs_set"
	 - 2、这里创建表和提交信息是一个函数
	 - 3、先连接到数据库，获取光标
	 - 4、设置表格的表头，或者说字段，栏目，涉及到MySQL的关键词，存到tem变量中
	 - 5、设置表格的名字，定为"blogs_set"注意这个s
	 - 6、创建MySQL语句 赋值给sql变量。并且用format传入变量信息。
	 - 7、尝试执行语句：cursor.execute(sql)，如果有了就算了，没有就创建
	 - 8、修饰传入数据的格式，字符串该加反斜杠的都加上
	 - 9、将表格的主体信息——博客集的属性信息存储进去
	 - 10、关闭数据库连接。

 - 5、调用log_id.write_id函数，如果之前没有，直接创建，如果有同名文件，洗掉，重新写。保证每次只有一个数据。
 - 6、调用plot_demo.drawBydata函数：
	 - 1、导入read_blogs_set_table_info模块
	 - 2、调用这个模块，在数据库中读取你传入的信息：
		 - 1、导入pymysql
		 - 2、连接数据库，创建sql语句
		 - 3、select你需要的字段。具体操作和存储差不多、
		 - 4、数据存在data变量中，但是需要对time这个字符串格式进行一个修改。这里可能上传到GitHub上已经没有这个bug了。
		 - 5、开始调用matplotlib的画图工具了：
			 - 1、横轴信息：获取时间，可以不考虑时间间隔，也可以把时间间隔加上，我目前没有设置好参数，但是都实现了。
			 - 2、纵轴信息：总访问量或者其他
			 - 3、设置图片保存的分辨率
			 - 4、设置x轴标签的内容和参数
			 - 5、保存图片，显示图片。
		 - 6、添加其他的画图函数，比如每个博客的连续三天访问量的柱状图
##后期的可视化过程和转EXE文件还没有更新，大家自己看博客和我的代码吧~
##博客地址：
[作为一个CSDN博主，如何更直接的获取成就感？——python2调用远程服务器定时爬取CSDN访问量存入MySQL数据库并可视化系列教程（一：项目由来）](https://blog.csdn.net/hehedadaq/article/details/82464556)
